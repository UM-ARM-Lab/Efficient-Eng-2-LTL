{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw/ltl.txt\", \"r\") as f:\n",
    "    raw_ltls = f.read().splitlines()\n",
    "    unique_ltls = set(raw_ltls)\n",
    "with open(\"raw/eng.txt\", 'r') as f:\n",
    "    raw_engs = f.read().splitlines()\n",
    "\n",
    "DPs = []\n",
    "for ltl, eng in zip(raw_ltls, raw_engs):\n",
    "    DPs.append({'ltl': ltl, 'eng': eng})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F B\n",
      "F C\n",
      "F Y\n",
      "F R\n",
      "F & R F Y\n",
      "F & R F Z\n",
      "F & C F B\n",
      "F & R F X\n",
      "F & R F C\n",
      "F & Y F B\n",
      "F & C F Y\n",
      "F & B F R\n",
      "F & B F C\n",
      "F & R F B\n",
      "F & C F R\n",
      "F & B F Y\n",
      "F & Y F C\n",
      "& F C G ! R\n",
      "& F Y G ! C\n",
      "& F R G ! C\n",
      "& F Y G ! B\n",
      "& F R G ! B\n",
      "& F C G ! Y\n",
      "& F B G ! R\n",
      "& F B G ! Y\n",
      "& F Y G ! R\n",
      "& F C G ! B\n",
      "& F B G ! C\n",
      "& F R G ! Y\n",
      "F & | R B F Y\n",
      "F & | R Y F B\n",
      "F & | Y B F C\n",
      "F & | R B F C\n",
      "F & | C Y F B\n",
      "F & | R Y F C\n",
      "F & | R C F B\n",
      "F & | C Y F R\n",
      "F & | C R F B\n",
      "F & | B Y F C\n"
     ]
    }
   ],
   "source": [
    "for ltl in sorted(unique_ltls, key=lambda x: len(x)):\n",
    "    print(ltl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean-up Domain, with augmentation\n",
      "Number of Data Points 3382\n",
      "Number of unique LTL expressions: 39\n",
      "Number of unique LTL structures: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Clean-up Domain, with augmentation\")\n",
    "print(\"Number of Data Points\", len(DPs))\n",
    "print(\"Number of unique LTL expressions:\", len(unique_ltls))\n",
    "print(\"Number of unique LTL structures:\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F & B F C\n",
      "go to the blue room keep going and stop when you reach the green room\n",
      "\n",
      "F R\n",
      "move to the red room\n",
      "\n",
      "& F C G ! Y\n",
      "go only through rooms that are not yellow to get to the green room\n",
      "\n",
      "F & | R Y F B\n",
      "go through the yellow or red room to reach the blue room\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seen_length = set()\n",
    "for dp in DPs:\n",
    "    if len(dp['ltl']) not in seen_length:\n",
    "        seen_length.add(len(dp['ltl']))\n",
    "        print(dp['ltl'])\n",
    "        print(dp['eng'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up LTL expressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Room_Types = [('B', 'go to the blue room'), ('R', 'go to the red room'), ('Y', 'go to the yellow room'), ('C', 'go to the green room')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "APs = [\n",
    "    {'ap': 'B', 'eng': 'go to the blue room'},\n",
    "    {'ap': 'R', 'eng': 'go to the red room'},\n",
    "    {'ap': 'Y', 'eng': 'go to the yellow room'},\n",
    "    {'ap': 'C', 'eng': 'go to the green room'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_A(ap1):\n",
    "    return {\n",
    "        'raw_ltl': f\"F {ap1['ap']}\",\n",
    "        'canonical_ltl': f\"finally {ap1['eng']}\",\n",
    "        'eng': f\"{ap1['eng']}\"}\n",
    "\n",
    "def build_type_B(room_1, room_2):\n",
    "    return {\n",
    "        \"raw_ltl\": f\"F & {room_1['ap']} F {room_2['ap']}\",\n",
    "        \"canonical_ltl\": f\"finally ( and (  {room_1['eng']} , finally ( {room_2['eng']} )  )  )\",\n",
    "        \"eng\": f\"{room_1['eng']} first, and then {room_2['eng']}\"}\n",
    "\n",
    "def build_type_C(room_1, room_2):\n",
    "    return {\n",
    "        \"raw_ltl\": f\"& F {room_1['ap']} G ! {room_2['ap']}\",\n",
    "        \"canonical_ltl\": f\"and ( finally ( {room_1['eng']} ) , globally ( not ( {room_2['eng']} ) ) )\",\n",
    "        \"eng\": f\"{room_1['eng']}, and do not ever {room_2['eng']}\"\n",
    "    }\n",
    "\n",
    "def build_type_D(room_1, room_2, room_3):\n",
    "    return {\n",
    "        \"raw_ltl\": f\"F & | {room_1['ap']} {room_2['ap']} F {room_3['ap']}\",\n",
    "        \"canonical_ltl\": f\"finally ( and ( or ( {room_1['eng']} , {room_2['eng']} ) , finally ( {room_3['eng']} ) ) )\",\n",
    "        \"eng\": f\"{room_1['eng']} or {room_2['eng']} to finally {room_3['eng']}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_seeds = []\n",
    "for r1 in APs:\n",
    "    translation_seeds.append(build_type_A(r1))\n",
    "    for r2 in APs:\n",
    "        if r1 == r2:\n",
    "            continue\n",
    "        translation_seeds.append(build_type_B(r1, r2))\n",
    "        translation_seeds.append(build_type_C(r1, r2))\n",
    "        for r3 in APs:\n",
    "            if r1 == r3 or r2 == r3:\n",
    "                continue\n",
    "            translation_seeds.append(build_type_D(r1, r2, r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "print(len(translation_seeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F & R F Z', 'F & R F X'}\n"
     ]
    }
   ],
   "source": [
    "seed_ltls = set([t['raw_ltl'] for t in translation_seeds])\n",
    "print(unique_ltls - seed_ltls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_seed_1 = {\n",
    "    \"raw_ltl\": \"F & R F X\",\n",
    "    \"canonical_ltl\": \"finally ( and (  go to the red room , finally ( go to the blue room with chair )  )  )\",\n",
    "    \"eng\": \"go to the red room and push the chair into the blue room\"\n",
    "}\n",
    "\n",
    "additional_seed_2 = {\n",
    "    \"raw_ltl\": \"F & R F Z\",\n",
    "    \"canonical_ltl\": \"finally ( and (  go to the red room , finally ( go to the green room with chair )  )  )\",\n",
    "    \"eng\": \"go to the red room and push the chair into the green room\"\n",
    "}\n",
    "\n",
    "translation_seeds.append(additional_seed_1)\n",
    "translation_seeds.append(additional_seed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translation_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "seed_ltls = set([t['raw_ltl'] for t in translation_seeds])\n",
    "print(unique_ltls - seed_ltls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the canonical decoding list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_decodings = {}\n",
    "for seed in translation_seeds:\n",
    "    canonical = seed['canonical_ltl']\n",
    "    possible_decodings[canonical] = {\n",
    "        'formula': canonical,\n",
    "        'raw': seed['raw_ltl'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"canonical.json\", 'w') as f:\n",
    "    f.write(json.dumps(possible_decodings, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save translation seed for zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_seed.jsonl\", \"w\") as f:\n",
    "    for dp in translation_seeds:\n",
    "        better_ltl = dp['canonical_ltl']\n",
    "        entry = {'canonical': better_ltl, 'formula': better_ltl, 'natural': dp['eng']}\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save golden data for evaluation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_canonical_mapping = {\n",
    "    seed['raw_ltl']: seed['canonical_ltl'] for seed in translation_seeds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3382"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ltl': 'F & B F C',\n",
       " 'eng': 'go to the blue room keep going and stop when you reach the green room'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"golden.jsonl\", \"w\") as f:\n",
    "    for dp in DPs:\n",
    "        entry = {\n",
    "            'canonical': raw_canonical_mapping[dp['ltl']],\n",
    "            'formula': raw_canonical_mapping[dp['ltl']],\n",
    "            'natural': dp['eng'],\n",
    "            'raw_ltl': dp['ltl'],\n",
    "        }\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('GPML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92a84f77637d1d47b588cbbaac9b07f8c628b67f58e672e955ed4902878afbbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
